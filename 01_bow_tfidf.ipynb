{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/notebook.ipynb)"
      ],
      "metadata": {
        "id": "p5CMnAlJuy3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag-of-Words (BoW), one of the simplest and most interpretable text representations. Text data can be converted into numerical representations and each sentence becomes a vector of word counts.\n"
      ],
      "metadata": {
        "id": "8aF0RDG0ixqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://scikit-learn.org/stable/user_guide.html\n",
        "%pip install scikit-learn"
      ],
      "metadata": {
        "id": "SNGiovTicqO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\"Dog bites man.\",\n",
        "        \"Man bites dog.\",\n",
        "        \"Dog eats meat.\",\n",
        "        \"Man eats food.\",\n",
        "        \"Cat likes milk and fish.\",\n",
        "        \"Dog likes meat and food.\"\n",
        "        ]\n",
        "\n",
        "processed_docs = [doc.lower().replace(\".\",\"\") for doc in docs]\n",
        "\n",
        "#look at the documents list\n",
        "print(\"Our corpus: \", processed_docs)\n"
      ],
      "metadata": {
        "id": "S0cJnQQBbn7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We use CountVectorizer from sklearn to learn a vocabulary and count word occurrences"
      ],
      "metadata": {
        "id": "G020XoaBmvOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Build a BOW representation for the corpus:\n",
        "  Step 1: scans all documents, collects unique words, builds the vocabulary, assigns column indices\n",
        "  Step 2: Uses the learned vocabulary produces a document Ã— term matrix\n",
        "  In short, preprocessing 'texts --> numbers'\n",
        "\"\"\"\n",
        "#https://scikit-learn.org/stable/modules/feature_extraction.html\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer() # create CountVector object, not vocab yet, learn vocab later in .fit\n",
        "bow_rep = count_vect.fit_transform(processed_docs) # two steps in one line: fit(processed_docs) and transform(processed_docs)\n",
        "bow_rep.shape   # dimension check"
      ],
      "metadata": {
        "id": "hdbmU1Txc_7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(bow_rep.toarray())\n",
        "plt.colorbar()\n",
        "plt.xlabel(\"Word index\")\n",
        "plt.ylabel(\"Document index\")\n",
        "plt.title(\"Bag-of-Words Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ML_sVuKje1d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the vocabulary mapping\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary_)"
      ],
      "metadata": {
        "id": "YTvw2Kqcd5VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at word and index mapping\n",
        "for i, word in enumerate(count_vect.get_feature_names_out()): # get all vocab from in column order while adding index\n",
        "    print(i, word)"
      ],
      "metadata": {
        "id": "R-U79o9CjzXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#See the BOW rep for the first and last documents\n",
        "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray()) #sparse matrix to array\n",
        "print(\"BoW representation for 'dog likes meat and food: \",bow_rep[-1].toarray())\n",
        "\n",
        "#Get the representation using this vocabulary, for a new text within the vacabulary range\n",
        "temp = count_vect.transform([\"dog and dog eats fish and food\"])\n",
        "print(\"Bow representation for 'dog and dog eats fish and food':\", temp.toarray())\n",
        "\n",
        "#Get the representation using this vocabulary, for a new text outside of the vacabulary range\n",
        "temp = count_vect.transform([\"human and animal are friends\"])\n",
        "print(\"Bow representation for 'human and animal are friends':\", temp.toarray())"
      ],
      "metadata": {
        "id": "XbFfrFSQfNlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF (Term Frequency-Inverse Document Frequency)"
      ],
      "metadata": {
        "id": "z8zePCHF6aw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import seaborn as sns\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_rep = tfidf_vect.fit_transform(processed_docs)\n",
        "\n",
        "print(f\"TF-IDF Matrix Shape: {tfidf_rep.shape}\")\n",
        "print(\"TF-IDF vocabulary: \", tfidf_vect.vocabulary_)\n"
      ],
      "metadata": {
        "id": "N5J_V7yL6c2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Heatmap via seaborn https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(tfidf_rep.toarray(),\n",
        "            annot=True,\n",
        "            fmt='.2f',\n",
        "            cmap='viridis',\n",
        "            xticklabels=tfidf_vect.get_feature_names_out(),\n",
        "            yticklabels=[f\"Doc {i+1}\" for i in range(len(docs))], #f-string\n",
        "            cbar_kws={'label': 'TF-IDF Score'})\n",
        "plt.xlabel(\"Words\", fontsize=12)\n",
        "plt.ylabel(\"Documents\", fontsize=12)\n",
        "plt.title(\"TF-IDF Matrix Heatmap\", fontsize=14, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "F0vDp4iqEsqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with exist text\n",
        "print(\"\\nTF-IDF for 'dog bites man': \", tfidf_rep[0].toarray())\n",
        "print(\"TF-IDF for 'dog likes meat and food': \", tfidf_rep[-1].toarray())\n",
        "\n",
        "\n",
        "# Test with new text\n",
        "temp_tfidf = tfidf_vect.transform([\"dog and dog eats fish and food\"])\n",
        "print(\"\\nTF-IDF for 'dog and dog eats fish and food':\", temp_tfidf.toarray())\n",
        "\n",
        "temp_tfidf = tfidf_vect.transform([\"human and animal are friends\"])\n",
        "print(\"TF-IDF for 'human and animal are friends':\", temp_tfidf.toarray())"
      ],
      "metadata": {
        "id": "3_p7B3OrFeFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking document similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "sim_matrix = cosine_similarity(tfidf_rep)\n",
        "print(\"Similarity matrix shape:\", sim_matrix.shape)\n",
        "print(\"\\nSimilarity raw matrix:\\n\", sim_matrix)"
      ],
      "metadata": {
        "id": "DmUhpEo2I8UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optionally make the display nicer\n",
        "labels = [f\"Doc {i+1}\" for i in range(len(processed_docs))]\n",
        "sim_df = pd.DataFrame(sim_matrix, index=labels, columns=labels)\n",
        "print(\"\\nSimilarity table:\")\n",
        "print(sim_df.round(3))"
      ],
      "metadata": {
        "id": "vu-JtoFAJ-gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### These representations treat every word as independent. Later, we'll see how Skip-gram and CBOW learn vectors where similar words are close together."
      ],
      "metadata": {
        "id": "rmX393Zyw1Rj"
      }
    }
  ]
}